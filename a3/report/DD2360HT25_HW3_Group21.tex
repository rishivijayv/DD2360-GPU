\documentclass[a4paper,10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[a4paper,
            bindingoffset=0.2in,
            left=1in,
            right=1in,
            top=1in,
            bottom=1in,
            footskip=.25in]{geometry}

%###############################################################################

%\input{~/layout/global_layout}


%###############################################################################

% packages begin

\usepackage[
  backend=biber,
  sortcites=true,
  style=alphabetic,
  eprint=true,
  backref=true
]{biblatex}
\addbibresource{bibliographie.bib}
\usepackage[acronym]{glossaries}
\usepackage{multirow}
\usepackage{euscript}[mathcal]
% e.g. \mathcal{A} for fancy letters in mathmode
\usepackage{amsmath,amssymb,amstext,amsthm}

\usepackage{mdframed}
\newmdtheoremenv[nobreak=true]{problem}{Problem}[subsection]
\newmdtheoremenv[nobreak=true]{claim}{Claim}[subsection]
\newtheorem{definition}{Definition}[subsection]
\newtheorem{lemma}{Lemma}[claim]
\newtheorem{plemma}{Lemma}[problem]

\usepackage{mathtools}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\usepackage{enumerate}
\usepackage[pdftex]{graphicx}
\usepackage{subcaption}
% 'draft' für schnelleres rendern mitübergeben -> [pdftex, draft]
% dadruch wird nicht das bild mitgerendered, sondern nur ein kasten mit bildname -> schont ressourcen

\usepackage{hyperref}

\usepackage{tikz}
\usetikzlibrary{arrows,automata,matrix,positioning,shapes}

% for adding non-formatted text to include source-code
\usepackage{listings}
\lstset{language=Python,basicstyle=\footnotesize}
% z.B.:
% \lstinputlisting{source_filename.py}
% \lstinputlisting[lanugage=Python, firstline=37, lastline=45]{source_filename.py}
%
% oder
%
% \begin{lstlisting}[frame=single]
% CODE HERE
%\end{lstlisting}
\usepackage{algorithm}
\usepackage{algpseudocode}

\usepackage{wasysym}

\usepackage{titling}
\usepackage{titlesec}
\usepackage[nocheck]{fancyhdr}
\usepackage{lastpage}

\usepackage{kantlipsum}
\usepackage[colorinlistoftodos,prependcaption,textsize=tiny]{todonotes}

% packages end
%###############################################################################

\pretitle{% add some rules
  \begin{center}
    \LARGE\bfseries
} %, make the fonts bigger, make the title (only) bold
\posttitle{%
  \end{center}%
  %\vskip .75em plus .25em minus .25em% increase the vertical spacing a bit, make this particular glue stretchier
}
\predate{%
  \begin{center}
    \normalsize
}
\postdate{%
  \end{center}%
}

\titleformat*{\section}{\Large\bfseries}
\titleformat*{\subsection}{\large\bfseries}
\titleformat*{\subsubsection}{\normalsize\bfseries}

\titleformat*{\paragraph}{\Large\bfseries}
\titleformat*{\subparagraph}{\large\bfseries}

%###############################################################################

\pagestyle{fancy}
\fancyhf{}
% l=left, c=center, r=right; e=even_pagenumber, o=odd_pagenumber; h=header, f=footer
% example: [lh] -> left header, [lof,ref] -> fotter left when odd, right when even
%\fancyhf[lh]{}
%\fancyhf[ch]{}
%\fancyhf[rh]{}
%\fancyhf[lf]{}
\fancyhf[cf]{\footnotesize Page \thepage\ of \pageref*{LastPage}}
%\fancyhf[rf]{}
\renewcommand{\headrule}{} % removes horizontal header line

% Fotter options for first page

\fancypagestyle{firstpagestyle}{
  \renewcommand{\thedate}{\textmd{}} % removes horizontal header line
  \fancyhf{}
  \fancyhf[lh]{\ttfamily M.Sc. Computer Science\\KTH Royal Institute of Technology}
  \fancyhf[rh]{\ttfamily Period 2\\\today}
  \fancyfoot[C]{\footnotesize Page \thepage\ of \pageref*{LastPage}}
  \renewcommand{\headrule}{} % removes horizontal header line
}
%###############################################################################

\newcommand\extrafootertext[1]{%
    \bgroup
    \renewcommand\thefootnote{\fnsymbol{footnote}}%
    \renewcommand\thempfootnote{\fnsymbol{mpfootnote}}%
    \footnotetext[0]{#1}%
    \egroup
}

%###############################################################################

\title{
  \normalsize{DD2356 HT25 Applied}\\
  \normalsize{GPU Programming}\\
  \large{Assignment 3}
}
\author{
  \small Paul Mayer\textsuperscript{\textdagger}\\[-0.75ex]
%  \footnotesize\texttt{MN: }\\[-1ex]
  \scriptsize\texttt{pmayer@kth.se}
  \and
  \small Rishi Vijayvargiya\textsuperscript{\textdagger}\\[-0.75ex]
%  \footnotesize\texttt{MN: }\\[-1ex]
  \scriptsize\texttt{rishiv@kth.se}
}
\date{}


%###############################################################################
% define Commands

\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\I}{\mathbb{I}}

\newcommand{\E}{\mathbb{E}}
\newcommand{\Prob}{\mathbb{P}}

\renewcommand{\epsilon}{\varepsilon}
% \newcommand{\ceil}[1]{\left\lceil #1 \right\rceil}
% \newcommand{\floor}[1]{\left\lfloor #1 \right\rfloor}


\newcommand{\itodo}[2][yellow]{\todo[inline, color=#1!40]{#2}}
\newcommand{\mtodo}[2][orange]{\todo[color=#1!40]{#2}}



%###############################################################################
\makeatletter
\renewcommand*{\@fnsymbol}[1]{\ensuremath{\ifcase#1\or \dagger\or \ddagger\or
   \mathsection\or \mathparagraph\or \|\or **\or \dagger\dagger
   \or \ddagger\ddagger \else\@ctrerr\fi}}
\makeatother
%###############################################################################

\begin{document}
\maketitle
\extrafootertext{\textsuperscript{\textdagger}Authors made equal contribution to the project}
\thispagestyle{firstpagestyle}
\vspace{1em}

% content begin
%

\section*{Prefix}
The code for our project was submitted as a zip file.
You can find code for the code-related questions of the assignment under \verb|q[x]/|, where \verb|x| is the question number. 

\tableofcontents
\newpage

\section{Exercise 1}
For this question, we assume the following convention: 
\begin{itemize}
\item We assume that $X$ is the number of columns (\verb|n| in the code)
\item We assume that $Y$ is the number of rows (\verb|m| in code)
\item We assume that a $64 \times 16$ CUDA block means that \verb|blockDim.x| is 64 and that \verb|blockDim.y| is 16. This means that the block has 64 columns and 16 rows. 
\end{itemize}

The \verb|PictureKernel| computes the indices that the current thread is responsible for, and executes code in the \verb|if| branch if the index is within range, or else does not do anything. Thus, we will have control divergence when some threads in a warp are within the range of the picture, and some threads are not. Thus, the question of control divergence boils down to: \textbf{how many warps has some threads in range and some threads out of range?}

\subsection{When X=800 and Y=600}
\label{sec:ex1_part1}
The image can be divided in to matrix of blocks, with $\ceil{800 / 64} = 13$ blocks in the X-direction and $\ceil{600 / 16} = 38$ blocks in the Y-direction. That is, this matrix of blocks (which we will call MoB) has 13 columns and 38 rows of blocks of CUDA size $64 \times 16$. Each block has $16 \times 64 = 1024$ threads, and each warp in a block has 32 threads. Thus, there are a total of $1024 / 32 = 32$ warps per block. There are $38 \times 13 = 494$ such blocks. So, the total number of warps generated during kernel execution are $494 \times 32 = 15808$.

We will now consider the topic of control divergence. For our case, this will happen either because of the last column of blocks in the MoB (except the last block in this column), or the last row of the MoB (except the last block in the row), or the last block in the MoB (ie, the block at row 38 and column 13). This is because only these blocks will have some threads that are within range of the picture and some threads that are out of range. We will call these Case I, II and III respectively and analyze these divergences separately

\begin{itemize}
\item \underline{Case I}: We know that in a block, threads are allocated to warps in a row-major order. In a $64 \times 16$ CUDA block, each row in the block has $64 / 32 = 2$ warps. For the 13th block in each row of MoB (except the last row), there are $800 \% 64 = 32$ threads that are in range for the picture and 32 threads that are out of range. Thus for this last block in each row of the MoB, there is \textbf{no divergence}, as each warp is either fully in range or fully out of range. 
\item \underline{Case II}: For the 38th block in each column of the MoB (except the last column), there are $600 \% 16 = 8$ rows of threads in a block that are in range for the picture and 8 rows of threads in a block that are out of range of the picture. However, since warps are allocated in row-major order, there is \textbf{no divergence} here either, since entire rows of threads are either within range or out of range. 
\item \underline{Case III}: The case of the last block can be treated in the same way: in the last 8 rows in the block, all threads are out of range. For each of the first 8 rows, 32 threads (1st warp) are within range, and 32 threads (2nd warp) are out of range. So, there is \textbf{no divergence} here either. 
\end{itemize}

So, combining our observations, there is \textbf{\underline{no control divergence}} in this configuration.

\subsection{When X=600 and Y=800}
\label{sec:ex1_part2}
We will use the same analysis conventions and terminology that we did for Section \ref{sec:ex1_part1}. In the MoB, there are $\ceil{600 / 64} = 10$ blocks in the X-direction and $\ceil{800 / 16} = 50$ blocks in the Y-direction (ie, 50 rows and 10 columns).  Also, note that $16 \times 50 = 800$, so there is no Case II to consider here as there are no blocks in the MoB where there are threads out of range in the Y-direction of the picture. 
\begin{itemize}
\item \underline{Case I}: For the 10th block in each row of MoB (except the last row), there are $600 \% 64 = 24$ threads that are in range for the picture and 40 threads that are out of range. Recall that each row of a block has 2 warps with 32 threads each. Thus, for blocks in Case I, there are 24 threads that are in range and 8 threads that are out of range for the 1st warp in each row of the block. The second warp in each row of the block is completely out of range and faces no divergence. Thus, for each row of a block in Case I, there is 1 divergent warp. In total, there are 16 rows in a block, giving us 16 divergent warps per block. There are exactly $\floor{800 / 16} = 800 / 16 = 50$ such blocks in the last column in the MoB. Thus, the total number of warps facing control divergence in Case I is $16 \times 50$ or \textbf{800 warps}.
\item \underline{Case II}: There are no blocks that will have some rows of threads in range and some rows of threads out of range, so this case is not a cause of divergence here.
\item \underline{Case III}: This was accounted for in Case I since there are no partial blocks (some rows of threads in range and some rows of threads out of range) in the Y-direction. 
\end{itemize}

Thus, in total, in this case there are \textbf{800 warps} that experience control divergence.

\subsection{When X=600 and Y=899}
Now in the MoB, there are $\ceil{600 / 64} = 10$ blocks in the X-direction and $\ceil{899 / 16} = 57$ blocks in the Y-direction (ie, 57 rows and 10 columns).
\begin{itemize}
\item \underline{Case I}: This is similar to Section \ref{sec:ex1_part2}, so the number of warps per thread block facing control divergence for blocks in the 10th column of the MoB is 16. There are $\floor{899 / 16} = 56$ such threads blocks (since we omit the very last thread block till Case III). So, there are a total of $16 \times 56$ warps facing control divergence in Case I, ie, \textbf{896 warps}.
\item \underline{Case II}: For the 57th block in each column of the MoB (except the last column), there are $899 \% 16 = 3$ rows of threads in a block that are in range of the picture and then 13 rows of blocks that are out of range. But again, since warps are allocated in row-major order, entire warps being in range or out of range means that for us, there is \textbf{no control divergence} form this case. 
\item \underline{Case III}: Finally, for the last block in the MoB (ie, the block at row 57 and column 10), there are $899 \% 16 = 3$ rows of threads that are partially in range and partially out of range. The remaining 13 rows of threads are completely out of range and thus have no control divergence. For these first 3 rows of threads, the first $600 \% 64 = 24$ threads are in range of the picture and the last 40 threads are out of range. Thus, similar to Case I here, each row has 1 warp (the first warp in each of the 3 rows) that has control divergence, giving us \textbf{3 warps} with control divergence in this case.
\end{itemize}

So, in total, there are $896 + 3$ or \textbf{899 warps} facing control divergence in this configuration.

\section{Exercise 2}
The file \verb|q2/vecAddKernel.cu| contains our implementation of the streamed and normal vector addition using CUDA. The major changes to the original file include using \textbf{pinned host memory} through calls to \verb|cudaHostAlloc| instead of \verb|malloc|, and the addition of the streamed way of distributing work for vector addition. The CUDA kernel itself is called \verb|addGpu| and remains unchanged from Assignment 1

For the streamed implementation, we first determine the number of segments the original array will be divided in to based on the provided \verb|S_seg|. We then create 4 streams as requested by the assignment, and then iterate through the segments, distributing them to the 4 streams in a \textbf{round-robin} fashion (segment \verb|i| goes to stream \verb|i \% 4|), taking care of appropriate boundary conditions. We use \verb|cudaMemcpyAsync| for D-to-H and H-to-D memory transfer. For the kernel launch configuration, we use 1024 threads per block, and the number of blocks that the kernel acts on is $\ceil{S_{seg} / 1024}$ (except for the last segment which might include less than $S_{seg}$ elements. Note that when timing the runtime of the streamed GPU vector addition, the runtime for the creation and destruction of streams is not included, but the time for async memory transfer, kernel launches are included. Similarly, the for the normal (non-streamed) version of vector addition on the GPU, the runtimes include the time for D-to-H and H-to-D transfers in addition to the kernel launch.

\subsection{Normal vs Streamed GPU Vector Addition}
\label{sec:q2_part1}
\begin{figure}[t]
  \begin{center}
    \includegraphics[width=.75\textwidth]{../images/q2/part1.png}
  \end{center}
  \caption{Normal vs Streamed GPU Vector Addition Keeping $S_{seg}$ Constant}\label{fig:ex2_part1}
\end{figure}
Figure \ref{fig:ex2_part1} shows the log-log plot comparing the runtime of the Normal GPU Vector Addition (from Assignment 1) with the Streamed Implementation. We vary the vector-length while keeping the segment size ($S_{seg}$) at a constant of 102,400. We see that for all vector lengths, the streamed version of vector addition is \textbf{faster} than the normal vector addition on the GPU. The reason for this is likely the communication-computation overlap, which allows each of the streams in the the streamed vector addition to begin computation independently of other streams instead of waiting for the entire data to be transferred before computing (which is the case with normal vector addition). 

We see that as the number of elements in the input vectors increase, so does the runtime of the streamed version (and the normal version). This is likely because we are keeping the number of streams and the segment size constant, and thus the same streams now need to deal with a higher number of segments, which makes the streamed version's runtime approach the runtime of the normal implementation. The cost of creating and handling the higher number of segments (for eg: more kernel launches) is also likely contributing to the increased runtime of the streamed vector addition as the input length increases. 

The raw data for the plot presented in Figure \ref{fig:ex2_part1} is available in the \verb|q2/normal_v_streams.txt| file. We see that we get a speedup of up to \textbf{15x} for the smallest vector length, with the speedup gradually decreasing as we increase the vector lengths and the streamed runtime approaches the normal runtime. The speedup in the streamed version for the longest vector length is around \textbf{1.44x}. The likely reasons for why the streamed version approaches the normal version in runtime as we increase the vector length but keep the number of streams and segment size constant was discussed above.

The python script to run the experiment is \verb|q2/normal_vs_streams.py|, which generates the results \verb|.txt| file above. To plot the file, the \verb|q2/plot.py| file was used. The runtimes were obtained on the School GPU Cluster with the H100 GPUs. 

\subsection{Profiling Using nsys}
We attempted to profile the code using \verb|nvprof| but kept running in to various issues (likely because both group members have MacOS). Some of the issues are document \href{https://canvas.kth.se/courses/57317/discussion_topics/513951}{here}. Eventually, thanks to Gabin Schieffer's suggestion, we used \verb|nsys| instead, and then visualized the generated profile using NVIDIA Nsight Systems, which seems to have worked.

The profiling was done on the H100 GPUs present on the School's GPU Cluster, and the following command was used: 
\begin{center}
\verb|nsys profile ./vecAdd 1024000 10240 0 0|
\end{center}

This generated a \verb|.nsys-rep| file which has been added to the \verb|q2/| directory in the code zip file. This run used a vector of length 1024000 with segment sizes of 10240. Only the streamed version of vector addition was performed here (refer to the \verb|README.md| for details on what the command line arguments for \verb|./vecAdd| mean). 

 \begin{figure}
\centering
\begin{subfigure}{0.8\textwidth}
    \includegraphics[width=\textwidth]{../images/q2/part2_htod_overlap.png}
    \caption{H-to-D Overlap with Computation}
    \label{fig:ex2_part2_dtoh}
\end{subfigure}
\hfill
\begin{subfigure}{0.8\textwidth}
    \includegraphics[width=\textwidth]{../images/q2/part2_dtoh_overlap.png}
    \caption{D-to-H Overlap with Computation}
    \label{fig:ex2_part2_htod}
\end{subfigure}
        
\caption{Instances H-to-D and D-to-H overlap with computation in the profiled code}
\label{fig:ex2_part2}
\end{figure}

Figure \ref{fig:ex2_part2} shows instances of H-to-D and D-to-H overlap with computation (the \verb|addGpu| kernel), showing that the usage of streams does indeed cause overlap of computation with communication (in both directions) in the 4 streams that we are using.

\subsection{Impact of Segment Size on Runtime}
\begin{figure}[t]
  \begin{center}
    \includegraphics[width=.75\textwidth]{../images/q2/part3.png}
  \end{center}
  \caption{Impact of Segment Size on Runtime of Streamed Vector Addition (keeping $n$ constant)}\label{fig:ex2_part3}
\end{figure}

Figure \ref{fig:ex2_part3} is a log-log plot which shows the impact of varying segment size on the runtime of the streamed version. The trend seems to be that the \textbf{runtime decreases} as the segment size increases. Thus, larger segments perform better than smaller segment sizes if the array length and the number of streams are the same. The primary reason for this can be the over head associated with the memory transfers and kernel launches, among other things. 

When there are a larger number of segments, we have more calls to \verb|cudaMemcpyAsync| and more kernel launches. While the memory copies are now async between different streams, there is likely still a overhead and  teardown cost associated with it. The same can be said for the kernel launches. Additionally, operating on segments of smaller size might also mean that the SM is not utilized to the fullest extent -- vector addition is a rather straightforward computation, and doing it on incredibly small segments would mean that the kernel launches are incredibly short lived and the computation might not take as long as the kernel launch overhead. 

We believe that these reasons explain the observations in Figure \ref{fig:ex2_part3}. The raw data for the plot presented in Figure \ref{fig:ex2_part3} is available in the \verb|q2/segments.txt| file.


The python script to run the experiment is \verb|q2/segments.py|, which generates the results \verb|.txt| file above. To plot the file, the \verb|q2/plot.py| file was used. The runtimes were obtained on the School GPU Cluster with the H100 GPUs. 

\section{Bonus}
Goal of this bonus section was to port the \verb|mover_PC()| function of a simplified particle-in-cell solver to the GPU.

\subsection{Implementation Design}
The main challenge of this task is to set up the data movement between the GPU and CPU.
This is particularly annoying, because the data is stored as arrays within \texttt{structs}, meaning, if copied to the GPU, the copied \texttt{struct} would just contain an invalid pointer (pointing to CPU memory).
We solved this using a two stage process. First we allocate the array on the GPU, then we allocate the \texttt{struct}, replacing the CPU pointer with the GPU pointer.

To actually parallelize the code, we made the following observation:
\begin{lstlisting}[language=c++, caption=Interchangeble for loop ordering, label=lst:bonus1]
// start subcycling
for (int i_sub = 0; i_sub < part->n_sub_cycles; i_sub++) {
  // move each particle with new fields
  for (int i = 0; i < part->nop; i++) {
    ...
  }
}
\end{lstlisting}
Listing~\ref{lst:bonus1} shows two for loops within the \verb|mover_PC| function.
The key observation is that we can change the ordering of these two loops without changing the behaviour of the code.
First, \verb|n_sub_cycles| is 1 for our test file, but more importantly, all particle computations are independent from each other.
Additionally, within the \verb|mover_PC| method, the electric fields are READ-ONLY.
This allows us to iterate first over all particles, and then perform the sub-cycling per particle.
Our parallelization strategy is to perform the loop for each particle in parallel.

\begin{lstlisting}[language=c++, caption=GPU Memory Allocation, label=lst:bonus2]
struct particles *d_part = nullptr;

struct particles l_part = *part;

FPpart *d_part_x = nullptr;
FPpart *d_part_y = nullptr;
FPpart *d_part_z = nullptr;
FPpart *d_part_u = nullptr;
FPpart *d_part_v = nullptr;
FPpart *d_part_w = nullptr;

cudaMalloc(&d_part_x, size_part);
cudaMalloc(&d_part_y, size_part);
cudaMalloc(&d_part_z, size_part);
cudaMalloc(&d_part_u, size_part);
cudaMalloc(&d_part_v, size_part);
cudaMalloc(&d_part_w, size_part);

cudaMemcpy(d_part_x, part->x, size_part, cudaMemcpyHostToDevice);
cudaMemcpy(d_part_y, part->y, size_part, cudaMemcpyHostToDevice);
cudaMemcpy(d_part_z, part->z, size_part, cudaMemcpyHostToDevice);
cudaMemcpy(d_part_u, part->u, size_part, cudaMemcpyHostToDevice);
cudaMemcpy(d_part_v, part->v, size_part, cudaMemcpyHostToDevice);
cudaMemcpy(d_part_w, part->w, size_part, cudaMemcpyHostToDevice);

cudaMalloc(&d_part, sizeof(struct particles));

cudaMemcpy(d_part, &l_part, sizeof(struct particles), cudaMemcpyHostToDevice);
\end{lstlisting}

Listing~\ref{lst:bonus2} demonstrates how the memory allocation is performed (only for the particle struct, the other ones follow are done correspondingly).
We want to highlight the creation of a local copy \verb|l_part| which we use to store the respective \verb|d_part_?| pointers.
When we then allocate and copy \verb|l_part| into \verb|d_part|, the \verb|struct| contains the device pointers instead of host pointers.

\subsection{Correctness}
We ran the simulation for the provided test file for 600 iterations.
The output files after the final iteration contain differences.
We attribute this to rounding/precision differences between the GPU and CPU.
Visualizing\footnote{Visualization of the \href{https://github.com/rishivijayv/DD2360-GPU/blob/main/a3/videos/cpu.avi}{CPU computation} and \href{https://github.com/rishivijayv/DD2360-GPU/blob/main/a3/videos/gpu.avi}{GPU computation}} the simulation does not show any visible distinctions.
A sensible next step would be to quantify the numerical errors, but reserve this for the project.

\subsection{Performance}
We ran both version for 50 iterations.
The output shows the average time spent in both the \verb|mover_PC| and \verb|?| method.
\itodo{insert runtimes, can't access gpu cluster rn for whatever reason}
We can clearly see \mtodo{insert analysis} blah blah blah.

\section{Appendix}

% content end
%###############################################################################

% \printbibliography

\end{document}
